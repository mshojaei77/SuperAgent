[
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Toolkit",
        "importPath": "phi.tools",
        "description": "phi.tools",
        "isExtraImport": true,
        "detail": "phi.tools",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "phi.utils.log",
        "description": "phi.utils.log",
        "isExtraImport": true,
        "detail": "phi.utils.log",
        "documentation": {}
    },
    {
        "label": "Assistant",
        "importPath": "phi.assistant",
        "description": "phi.assistant",
        "isExtraImport": true,
        "detail": "phi.assistant",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "PyPDFLoader",
        "importPath": "langchain_community.document_loaders",
        "description": "langchain_community.document_loaders",
        "isExtraImport": true,
        "detail": "langchain_community.document_loaders",
        "documentation": {}
    },
    {
        "label": "PyPDFLoader",
        "importPath": "langchain_community.document_loaders",
        "description": "langchain_community.document_loaders",
        "isExtraImport": true,
        "detail": "langchain_community.document_loaders",
        "documentation": {}
    },
    {
        "label": "requests",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "requests",
        "description": "requests",
        "detail": "requests",
        "documentation": {}
    },
    {
        "label": "BeautifulSoup",
        "importPath": "bs4",
        "description": "bs4",
        "isExtraImport": true,
        "detail": "bs4",
        "documentation": {}
    },
    {
        "label": "urlparse",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "openai",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "openai",
        "description": "openai",
        "detail": "openai",
        "documentation": {}
    },
    {
        "label": "OpenAI",
        "importPath": "openai",
        "description": "openai",
        "isExtraImport": true,
        "detail": "openai",
        "documentation": {}
    },
    {
        "label": "groq",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "groq",
        "description": "groq",
        "detail": "groq",
        "documentation": {}
    },
    {
        "label": "together",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "together",
        "description": "together",
        "detail": "together",
        "documentation": {}
    },
    {
        "label": "cohere",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "cohere",
        "description": "cohere",
        "detail": "cohere",
        "documentation": {}
    },
    {
        "label": "g4f",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "g4f",
        "description": "g4f",
        "detail": "g4f",
        "documentation": {}
    },
    {
        "label": "ollama",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "ollama",
        "description": "ollama",
        "detail": "ollama",
        "documentation": {}
    },
    {
        "label": "ChatOpenAI",
        "importPath": "langchain_openai.chat_models",
        "description": "langchain_openai.chat_models",
        "isExtraImport": true,
        "detail": "langchain_openai.chat_models",
        "documentation": {}
    },
    {
        "label": "ChatOpenAI",
        "importPath": "langchain_openai.chat_models",
        "description": "langchain_openai.chat_models",
        "isExtraImport": true,
        "detail": "langchain_openai.chat_models",
        "documentation": {}
    },
    {
        "label": "OpenAIEmbeddings",
        "importPath": "langchain_openai.embeddings",
        "description": "langchain_openai.embeddings",
        "isExtraImport": true,
        "detail": "langchain_openai.embeddings",
        "documentation": {}
    },
    {
        "label": "OpenAIEmbeddings",
        "importPath": "langchain_openai.embeddings",
        "description": "langchain_openai.embeddings",
        "isExtraImport": true,
        "detail": "langchain_openai.embeddings",
        "documentation": {}
    },
    {
        "label": "StrOutputParser",
        "importPath": "langchain_core.output_parsers",
        "description": "langchain_core.output_parsers",
        "isExtraImport": true,
        "detail": "langchain_core.output_parsers",
        "documentation": {}
    },
    {
        "label": "StrOutputParser",
        "importPath": "langchain_core.output_parsers",
        "description": "langchain_core.output_parsers",
        "isExtraImport": true,
        "detail": "langchain_core.output_parsers",
        "documentation": {}
    },
    {
        "label": "PDFLoader",
        "importPath": "Tools.PdfFileLoader",
        "description": "Tools.PdfFileLoader",
        "isExtraImport": true,
        "detail": "Tools.PdfFileLoader",
        "documentation": {}
    },
    {
        "label": "WebScraper",
        "importPath": "Tools.WebLoader",
        "description": "Tools.WebLoader",
        "isExtraImport": true,
        "detail": "Tools.WebLoader",
        "documentation": {}
    },
    {
        "label": "RecursiveCharacterTextSplitter",
        "importPath": "langchain.text_splitter",
        "description": "langchain.text_splitter",
        "isExtraImport": true,
        "detail": "langchain.text_splitter",
        "documentation": {}
    },
    {
        "label": "FAISS",
        "importPath": "langchain_community.vectorstores",
        "description": "langchain_community.vectorstores",
        "isExtraImport": true,
        "detail": "langchain_community.vectorstores",
        "documentation": {}
    },
    {
        "label": "RunnableParallel",
        "importPath": "langchain_core.runnables",
        "description": "langchain_core.runnables",
        "isExtraImport": true,
        "detail": "langchain_core.runnables",
        "documentation": {}
    },
    {
        "label": "RunnablePassthrough",
        "importPath": "langchain_core.runnables",
        "description": "langchain_core.runnables",
        "isExtraImport": true,
        "detail": "langchain_core.runnables",
        "documentation": {}
    },
    {
        "label": "ChatPromptTemplate",
        "importPath": "langchain.prompts",
        "description": "langchain.prompts",
        "isExtraImport": true,
        "detail": "langchain.prompts",
        "documentation": {}
    },
    {
        "label": "streamlit",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "streamlit",
        "description": "streamlit",
        "detail": "streamlit",
        "documentation": {}
    },
    {
        "label": "WebAssistantAgent",
        "importPath": "ChatWithWebsite",
        "description": "ChatWithWebsite",
        "isExtraImport": true,
        "detail": "ChatWithWebsite",
        "documentation": {}
    },
    {
        "label": "DuckDuckGo",
        "kind": 6,
        "importPath": "Tools.DuckduckgoSearch",
        "description": "Tools.DuckduckgoSearch",
        "peekOfCode": "class DuckDuckGo(Toolkit):\n    def __init__(\n        self,\n        search: bool = True,\n        news: bool = True,\n        fixed_max_results: Optional[int] = None,\n        headers: Optional[Any] = None,\n        proxy: Optional[str] = None,\n        proxies: Optional[Any] = None,\n        timeout: Optional[int] = 10,",
        "detail": "Tools.DuckduckgoSearch",
        "documentation": {}
    },
    {
        "label": "assistant",
        "kind": 5,
        "importPath": "Tools.DuckduckgoSearch",
        "description": "Tools.DuckduckgoSearch",
        "peekOfCode": "assistant = Assistant(tools=[DuckDuckGo()], show_tool_calls=True)\nassistant.print_response(\"Radical AI Company internship?\", markdown=True)",
        "detail": "Tools.DuckduckgoSearch",
        "documentation": {}
    },
    {
        "label": "PDFLoader",
        "kind": 6,
        "importPath": "Tools.PdfFileLoader",
        "description": "Tools.PdfFileLoader",
        "peekOfCode": "class PDFLoader:\n    def __init__(self, file_name):\n        self.file_name = file_name\n        self.loader = PyPDFLoader(self.file_name)\n    def load_and_split(self):\n        return self.loader.load_and_split()\n# Usage\nfile_name = \"example.pdf\"\npdf_loader = PDFLoader(file_name)\npages = pdf_loader.load_and_split()",
        "detail": "Tools.PdfFileLoader",
        "documentation": {}
    },
    {
        "label": "file_name",
        "kind": 5,
        "importPath": "Tools.PdfFileLoader",
        "description": "Tools.PdfFileLoader",
        "peekOfCode": "file_name = \"example.pdf\"\npdf_loader = PDFLoader(file_name)\npages = pdf_loader.load_and_split()\n#converting to txt\n'''f = open(\"example.txt\", \"w\", encoding=\"utf-8\")\nfor page in pages:\n    f.write(str(page.page_content).encode('utf-8', 'replace').decode('utf-8'))\n    f.write(\"------\\n\")\n    f.write(str(page.metadata))'''",
        "detail": "Tools.PdfFileLoader",
        "documentation": {}
    },
    {
        "label": "pdf_loader",
        "kind": 5,
        "importPath": "Tools.PdfFileLoader",
        "description": "Tools.PdfFileLoader",
        "peekOfCode": "pdf_loader = PDFLoader(file_name)\npages = pdf_loader.load_and_split()\n#converting to txt\n'''f = open(\"example.txt\", \"w\", encoding=\"utf-8\")\nfor page in pages:\n    f.write(str(page.page_content).encode('utf-8', 'replace').decode('utf-8'))\n    f.write(\"------\\n\")\n    f.write(str(page.metadata))'''",
        "detail": "Tools.PdfFileLoader",
        "documentation": {}
    },
    {
        "label": "pages",
        "kind": 5,
        "importPath": "Tools.PdfFileLoader",
        "description": "Tools.PdfFileLoader",
        "peekOfCode": "pages = pdf_loader.load_and_split()\n#converting to txt\n'''f = open(\"example.txt\", \"w\", encoding=\"utf-8\")\nfor page in pages:\n    f.write(str(page.page_content).encode('utf-8', 'replace').decode('utf-8'))\n    f.write(\"------\\n\")\n    f.write(str(page.metadata))'''",
        "detail": "Tools.PdfFileLoader",
        "documentation": {}
    },
    {
        "label": "'''f",
        "kind": 5,
        "importPath": "Tools.PdfFileLoader",
        "description": "Tools.PdfFileLoader",
        "peekOfCode": "'''f = open(\"example.txt\", \"w\", encoding=\"utf-8\")\nfor page in pages:\n    f.write(str(page.page_content).encode('utf-8', 'replace').decode('utf-8'))\n    f.write(\"------\\n\")\n    f.write(str(page.metadata))'''",
        "detail": "Tools.PdfFileLoader",
        "documentation": {}
    },
    {
        "label": "WebScraper",
        "kind": 6,
        "importPath": "Tools.WebLoader",
        "description": "Tools.WebLoader",
        "peekOfCode": "class WebScraper:\n    def __init__(self, parser='html.parser', headers=None, proxy=None, timeout=10, cache_expiry=3600, max_cache_size=1000, max_workers=None):\n        self.parser = parser\n        self.proxy = proxy\n        self.timeout = timeout\n        self.cache_expiry = cache_expiry\n        self.max_cache_size = max_cache_size\n        self.max_workers = max_workers\n        self.cache = {}\n        if headers:",
        "detail": "Tools.WebLoader",
        "documentation": {}
    },
    {
        "label": "LLM",
        "kind": 6,
        "importPath": "api_llms",
        "description": "api_llms",
        "peekOfCode": "class LLM:\n    def __init__(self, api_key=None, model=None, system_prompt=\"You are a helpful assistant\", user_prompt=None):\n        self.api_key = api_key\n        self.model = model\n        self.system_prompt = system_prompt\n        self.user_prompt = user_prompt\n    def openai_llm(self):\n        client = openai.OpenAI(api_key=self.api_key)\n        completion = client.chat.completions.create(\n            model=self.model,",
        "detail": "api_llms",
        "documentation": {}
    },
    {
        "label": "OPENAI_API_KEY",
        "kind": 5,
        "importPath": "ChatWithPDF",
        "description": "ChatWithPDF",
        "peekOfCode": "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\nllm_model = \"gpt-3.5-turbo\"\nllm_temperature = \"0.7\"\nllm_streaming=True\n#embedding\nembedding_model = 'text-embedding-ada-002'\nembedding_chunk_size = 10000\n#loader\nfile_name = \"example.pdf\"\npdf_loader = PDFLoader(file_name)",
        "detail": "ChatWithPDF",
        "documentation": {}
    },
    {
        "label": "llm_model",
        "kind": 5,
        "importPath": "ChatWithPDF",
        "description": "ChatWithPDF",
        "peekOfCode": "llm_model = \"gpt-3.5-turbo\"\nllm_temperature = \"0.7\"\nllm_streaming=True\n#embedding\nembedding_model = 'text-embedding-ada-002'\nembedding_chunk_size = 10000\n#loader\nfile_name = \"example.pdf\"\npdf_loader = PDFLoader(file_name)\npages = pdf_loader.load_and_split()",
        "detail": "ChatWithPDF",
        "documentation": {}
    },
    {
        "label": "llm_temperature",
        "kind": 5,
        "importPath": "ChatWithPDF",
        "description": "ChatWithPDF",
        "peekOfCode": "llm_temperature = \"0.7\"\nllm_streaming=True\n#embedding\nembedding_model = 'text-embedding-ada-002'\nembedding_chunk_size = 10000\n#loader\nfile_name = \"example.pdf\"\npdf_loader = PDFLoader(file_name)\npages = pdf_loader.load_and_split()\n#instances",
        "detail": "ChatWithPDF",
        "documentation": {}
    },
    {
        "label": "embedding_model",
        "kind": 5,
        "importPath": "ChatWithPDF",
        "description": "ChatWithPDF",
        "peekOfCode": "embedding_model = 'text-embedding-ada-002'\nembedding_chunk_size = 10000\n#loader\nfile_name = \"example.pdf\"\npdf_loader = PDFLoader(file_name)\npages = pdf_loader.load_and_split()\n#instances\nmodel = ChatOpenAI(api_key=OPENAI_API_KEY, model=llm_model, temperature=llm_temperature,streaming=llm_streaming)\nembeddings = OpenAIEmbeddings(api_key=OPENAI_API_KEY,model=embedding_model,chunk_size=embedding_chunk_size)\nparser = StrOutputParser()",
        "detail": "ChatWithPDF",
        "documentation": {}
    },
    {
        "label": "embedding_chunk_size",
        "kind": 5,
        "importPath": "ChatWithPDF",
        "description": "ChatWithPDF",
        "peekOfCode": "embedding_chunk_size = 10000\n#loader\nfile_name = \"example.pdf\"\npdf_loader = PDFLoader(file_name)\npages = pdf_loader.load_and_split()\n#instances\nmodel = ChatOpenAI(api_key=OPENAI_API_KEY, model=llm_model, temperature=llm_temperature,streaming=llm_streaming)\nembeddings = OpenAIEmbeddings(api_key=OPENAI_API_KEY,model=embedding_model,chunk_size=embedding_chunk_size)\nparser = StrOutputParser()\n#prompt template",
        "detail": "ChatWithPDF",
        "documentation": {}
    },
    {
        "label": "file_name",
        "kind": 5,
        "importPath": "ChatWithPDF",
        "description": "ChatWithPDF",
        "peekOfCode": "file_name = \"example.pdf\"\npdf_loader = PDFLoader(file_name)\npages = pdf_loader.load_and_split()\n#instances\nmodel = ChatOpenAI(api_key=OPENAI_API_KEY, model=llm_model, temperature=llm_temperature,streaming=llm_streaming)\nembeddings = OpenAIEmbeddings(api_key=OPENAI_API_KEY,model=embedding_model,chunk_size=embedding_chunk_size)\nparser = StrOutputParser()\n#prompt template\ncontext = \"my name is mohammad\"\nquestion = \"what is my name?\"",
        "detail": "ChatWithPDF",
        "documentation": {}
    },
    {
        "label": "pdf_loader",
        "kind": 5,
        "importPath": "ChatWithPDF",
        "description": "ChatWithPDF",
        "peekOfCode": "pdf_loader = PDFLoader(file_name)\npages = pdf_loader.load_and_split()\n#instances\nmodel = ChatOpenAI(api_key=OPENAI_API_KEY, model=llm_model, temperature=llm_temperature,streaming=llm_streaming)\nembeddings = OpenAIEmbeddings(api_key=OPENAI_API_KEY,model=embedding_model,chunk_size=embedding_chunk_size)\nparser = StrOutputParser()\n#prompt template\ncontext = \"my name is mohammad\"\nquestion = \"what is my name?\"\nprompt = f\"\"\"",
        "detail": "ChatWithPDF",
        "documentation": {}
    },
    {
        "label": "pages",
        "kind": 5,
        "importPath": "ChatWithPDF",
        "description": "ChatWithPDF",
        "peekOfCode": "pages = pdf_loader.load_and_split()\n#instances\nmodel = ChatOpenAI(api_key=OPENAI_API_KEY, model=llm_model, temperature=llm_temperature,streaming=llm_streaming)\nembeddings = OpenAIEmbeddings(api_key=OPENAI_API_KEY,model=embedding_model,chunk_size=embedding_chunk_size)\nparser = StrOutputParser()\n#prompt template\ncontext = \"my name is mohammad\"\nquestion = \"what is my name?\"\nprompt = f\"\"\"\nAnswer the question based on the context below. If you can't ",
        "detail": "ChatWithPDF",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "ChatWithPDF",
        "description": "ChatWithPDF",
        "peekOfCode": "model = ChatOpenAI(api_key=OPENAI_API_KEY, model=llm_model, temperature=llm_temperature,streaming=llm_streaming)\nembeddings = OpenAIEmbeddings(api_key=OPENAI_API_KEY,model=embedding_model,chunk_size=embedding_chunk_size)\nparser = StrOutputParser()\n#prompt template\ncontext = \"my name is mohammad\"\nquestion = \"what is my name?\"\nprompt = f\"\"\"\nAnswer the question based on the context below. If you can't \nanswer the question, reply \"I don't know\".\nContext: {context}",
        "detail": "ChatWithPDF",
        "documentation": {}
    },
    {
        "label": "embeddings",
        "kind": 5,
        "importPath": "ChatWithPDF",
        "description": "ChatWithPDF",
        "peekOfCode": "embeddings = OpenAIEmbeddings(api_key=OPENAI_API_KEY,model=embedding_model,chunk_size=embedding_chunk_size)\nparser = StrOutputParser()\n#prompt template\ncontext = \"my name is mohammad\"\nquestion = \"what is my name?\"\nprompt = f\"\"\"\nAnswer the question based on the context below. If you can't \nanswer the question, reply \"I don't know\".\nContext: {context}\nQuestion: {question}",
        "detail": "ChatWithPDF",
        "documentation": {}
    },
    {
        "label": "parser",
        "kind": 5,
        "importPath": "ChatWithPDF",
        "description": "ChatWithPDF",
        "peekOfCode": "parser = StrOutputParser()\n#prompt template\ncontext = \"my name is mohammad\"\nquestion = \"what is my name?\"\nprompt = f\"\"\"\nAnswer the question based on the context below. If you can't \nanswer the question, reply \"I don't know\".\nContext: {context}\nQuestion: {question}\n\"\"\"",
        "detail": "ChatWithPDF",
        "documentation": {}
    },
    {
        "label": "context",
        "kind": 5,
        "importPath": "ChatWithPDF",
        "description": "ChatWithPDF",
        "peekOfCode": "context = \"my name is mohammad\"\nquestion = \"what is my name?\"\nprompt = f\"\"\"\nAnswer the question based on the context below. If you can't \nanswer the question, reply \"I don't know\".\nContext: {context}\nQuestion: {question}\n\"\"\"\n#running\n#chain =  model | parser ",
        "detail": "ChatWithPDF",
        "documentation": {}
    },
    {
        "label": "question",
        "kind": 5,
        "importPath": "ChatWithPDF",
        "description": "ChatWithPDF",
        "peekOfCode": "question = \"what is my name?\"\nprompt = f\"\"\"\nAnswer the question based on the context below. If you can't \nanswer the question, reply \"I don't know\".\nContext: {context}\nQuestion: {question}\n\"\"\"\n#running\n#chain =  model | parser \n#result = chain.invoke(prompt)",
        "detail": "ChatWithPDF",
        "documentation": {}
    },
    {
        "label": "prompt",
        "kind": 5,
        "importPath": "ChatWithPDF",
        "description": "ChatWithPDF",
        "peekOfCode": "prompt = f\"\"\"\nAnswer the question based on the context below. If you can't \nanswer the question, reply \"I don't know\".\nContext: {context}\nQuestion: {question}\n\"\"\"\n#running\n#chain =  model | parser \n#result = chain.invoke(prompt)\n#print(result)",
        "detail": "ChatWithPDF",
        "documentation": {}
    },
    {
        "label": "#chain",
        "kind": 5,
        "importPath": "ChatWithPDF",
        "description": "ChatWithPDF",
        "peekOfCode": "#chain =  model | parser \n#result = chain.invoke(prompt)\n#print(result)\nif __name__ == \"__main__\":\n    path = input(\"enter the [df path]: \")\n    user_input = input(\"ask anything? \")\n    agent = PdfAssistantAgent()\n    answer = agent.execute(path, user_input)\n    print(answer)",
        "detail": "ChatWithPDF",
        "documentation": {}
    },
    {
        "label": "#result",
        "kind": 5,
        "importPath": "ChatWithPDF",
        "description": "ChatWithPDF",
        "peekOfCode": "#result = chain.invoke(prompt)\n#print(result)\nif __name__ == \"__main__\":\n    path = input(\"enter the [df path]: \")\n    user_input = input(\"ask anything? \")\n    agent = PdfAssistantAgent()\n    answer = agent.execute(path, user_input)\n    print(answer)",
        "detail": "ChatWithPDF",
        "documentation": {}
    },
    {
        "label": "WebAssistantAgent",
        "kind": 6,
        "importPath": "ChatWithWebsite",
        "description": "ChatWithWebsite",
        "peekOfCode": "class WebAssistantAgent:\n    def __init__(self):\n        load_dotenv()\n        self.OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n        self.model = ChatOpenAI(openai_api_key=self.OPENAI_API_KEY, model=\"gpt-3.5-turbo\")\n        self.embeddings = OpenAIEmbeddings()\n        self.scraper = WebScraper(parser='html.parser', timeout=10, cache_expiry=3600, max_cache_size=1000)\n        self.parser = StrOutputParser()\n        self.text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n    def execute(self, url: str, user_input: str):",
        "detail": "ChatWithWebsite",
        "documentation": {}
    },
    {
        "label": "agent",
        "kind": 5,
        "importPath": "UI",
        "description": "UI",
        "peekOfCode": "agent = WebAssistantAgent()\nwith st.sidebar:\n    st.header('Web Assistant', divider='violet')\n    url = st.text_input(\"Enter Website URL\")\nif \"messages\" not in st.session_state:\n    st.session_state.messages = []\nuser_input = st.chat_input(\"Talk with me\")\nfor message in st.session_state.messages:\n    with st.chat_message(message[\"role\"]):\n        st.markdown(message[\"content\"])",
        "detail": "UI",
        "documentation": {}
    },
    {
        "label": "user_input",
        "kind": 5,
        "importPath": "UI",
        "description": "UI",
        "peekOfCode": "user_input = st.chat_input(\"Talk with me\")\nfor message in st.session_state.messages:\n    with st.chat_message(message[\"role\"]):\n        st.markdown(message[\"content\"])\nif user_input:\n    with st.chat_message(\"user\"):\n        st.markdown(user_input)\n    st.session_state.messages.append({\"role\": \"user\", \"content\": user_input})\n    conversation_history = [{\"role\": m[\"role\"], \"content\": m[\"content\"]} for m in st.session_state.messages]\n    with st.chat_message(\"assistant\"):",
        "detail": "UI",
        "documentation": {}
    }
]